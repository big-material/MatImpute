{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T10:03:27.912802Z",
     "start_time": "2024-05-08T10:03:27.909330Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "# label encoding\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T10:03:27.941876Z",
     "start_time": "2024-05-08T10:03:27.928481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type of glass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type of glass\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0              0\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0              0\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0              0\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0              0\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0              0\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...            ...\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0              5\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0              5\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0              5\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0              5\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0              5\n",
       "\n",
       "[214 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/Glass.csv\")\n",
    "df[\"Type of glass\"] = df[\"Type of glass\"].astype(\"category\")\n",
    "le = LabelEncoder()\n",
    "df[\"Type of glass\"] = le.fit_transform(df[\"Type of glass\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T10:03:27.988701Z",
     "start_time": "2024-05-08T10:03:27.983803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI               float64\n",
       "Na               float64\n",
       "Mg               float64\n",
       "Al               float64\n",
       "Si               float64\n",
       "K                float64\n",
       "Ca               float64\n",
       "Ba               float64\n",
       "Fe               float64\n",
       "Type of glass      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T10:03:27.994439Z",
     "start_time": "2024-05-08T10:03:27.989844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type of glass'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T10:03:28.030363Z",
     "start_time": "2024-05-08T10:03:27.995563Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\miniconda\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:149: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "from Impute import fill_with_et\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "\n",
    "class EtImputer(ImputerPlugin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._model = fill_with_et\n",
    "\n",
    "    @staticmethod\n",
    "    def name():\n",
    "        return \"et\"\n",
    "\n",
    "    @staticmethod\n",
    "    def hyperparameter_space():\n",
    "        return []\n",
    "\n",
    "    def _fit(self, *args, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def _transform(self, df):\n",
    "        # 按照缺失值的比例进行排序\n",
    "        miss_rate = df.isnull().sum() / df.shape[0]\n",
    "        cols = miss_rate.sort_values().index.tolist()\n",
    "        cols = [col for col in cols if miss_rate[col] > 0]\n",
    "        for col in cols:\n",
    "            df_col_filled = self._model(df, col)\n",
    "            df[col] = df_col_filled[col]\n",
    "        return df\n",
    "\n",
    "\n",
    "imputers.add(\"et\", EtImputer)\n",
    "\n",
    "hyper = imputers.get(\"hyperimpute\", n_inner_iter=1)\n",
    "et = imputers.get(\"et\")\n",
    "missforest = imputers.get(\"missforest\", max_iter=1)\n",
    "gain = imputers.get(\"gain\", n_epochs=10)\n",
    "sinkhorn = imputers.get(\"sinkhorn\", n_epochs=10)\n",
    "mean = imputers.get(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T06:34:00.427099Z",
     "start_time": "2024-05-09T06:33:10.486929Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import scienceplots\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# plt.style.use(['science','no-latex'])\n",
    "# # set font as times new roman\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# target_col = \"Type of glass\"\n",
    "# X = df.drop(target_col, axis=1)\n",
    "# y = df[target_col]\n",
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# et_all_test_preds = []\n",
    "# et_all_scores = []\n",
    "# et_all_f1_scores = []\n",
    "\n",
    "# hyper_all_test_preds = []\n",
    "# hyper_all_scores = []\n",
    "# hyper_all_f1_scores = []\n",
    "\n",
    "# missforest_all_test_preds = []\n",
    "# missforest_all_scores = []\n",
    "# missforest_all_f1_scores = []\n",
    "\n",
    "# ori_all_test_preds = []\n",
    "# ori_all_scores = []\n",
    "# ori_all_f1_scores = []\n",
    "\n",
    "# gain_all_test_preds = []\n",
    "# gain_all_scores = []\n",
    "# gain_all_f1_scores = []\n",
    "\n",
    "# sinkhorn_all_test_preds = []\n",
    "# sinkhorn_all_scores = []\n",
    "# sinkhorn_all_f1_scores = []\n",
    "\n",
    "# mean_all_test_preds = []\n",
    "# mean_all_scores = []\n",
    "# mean_all_f1_scores = []\n",
    "\n",
    "# y_test_all = []\n",
    "\n",
    "# for i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "#     X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#     y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "#     df_train = pd.concat([X_train, y_train], axis=1)\n",
    "#     df_test = pd.concat([X_test, y_test], axis=1)\n",
    "#     # reset the index\n",
    "#     df_train = df_train.reset_index(drop=True)\n",
    "#     df_test = df_test.reset_index(drop=True)\n",
    "#     X_train = df_train.drop(target_col, axis=1)\n",
    "#     y_train = df_train[target_col]\n",
    "#     X_test = df_test.drop(target_col, axis=1)\n",
    "#     y_test = df_test[target_col]\n",
    "\n",
    "#     cols = X_train.columns\n",
    "#     X_train = X_train.to_numpy()\n",
    "#     X_train_nan = simulate_nan(X_train, 0.1)['X_incomp']\n",
    "#     X_train_nan = pd.DataFrame(X_train_nan, columns=cols)\n",
    "\n",
    "#     X_train_imputed_hyper = hyper.fit_transform(X_train_nan.copy())\n",
    "#     X_train_imputed_et = et.fit_transform(X_train_nan.copy())\n",
    "#     X_train_imputed_missforest = missforest.fit_transform(X_train_nan.copy())\n",
    "#     X_train_imputed_gain = gain.fit_transform(X_train_nan.copy())\n",
    "#     X_train_imputed_sinkhorn = sinkhorn.fit_transform(X_train_nan.copy())\n",
    "#     X_train_imputed_mean = mean.fit_transform(X_train_nan.copy())\n",
    "\n",
    "#     clf_hyper = RandomForestClassifier(n_estimators=500)\n",
    "#     clf_hyper.fit(X_train_imputed_hyper, y_train)\n",
    "#     y_pred_hyper = clf_hyper.predict(X_test)\n",
    "#     print(\"Accuracy (hyperimpute):\", accuracy_score(y_test, y_pred_hyper))\n",
    "#     hyper_all_scores.append(accuracy_score(y_test, y_pred_hyper))\n",
    "#     hyper_all_test_preds.extend(y_pred_hyper)\n",
    "#     hyper_all_f1_scores.append(f1_score(y_test, y_pred_hyper, average='weighted'))\n",
    "\n",
    "#     clf_et = RandomForestClassifier(n_estimators=500)\n",
    "#     clf_et.fit(X_train_imputed_et, y_train)\n",
    "#     y_pred_et = clf_et.predict(X_test)\n",
    "#     print(\"Accuracy (et):\", accuracy_score(y_test, y_pred_et))\n",
    "#     et_all_scores.append(accuracy_score(y_test, y_pred_et))\n",
    "#     et_all_test_preds.extend(y_pred_et)\n",
    "#     et_all_f1_scores.append(f1_score(y_test, y_pred_et, average='weighted'))\n",
    "\n",
    "#     clf_missforest = RandomForestClassifier(n_estimators=500)\n",
    "#     clf_missforest.fit(X_train_imputed_missforest, y_train)\n",
    "#     y_pred_missforest = clf_missforest.predict(X_test)\n",
    "#     print(\"Accuracy (missforest):\", accuracy_score(y_test, y_pred_missforest))\n",
    "#     missforest_all_scores.append(accuracy_score(y_test, y_pred_missforest))\n",
    "#     missforest_all_test_preds.extend(y_pred_missforest)\n",
    "#     missforest_all_f1_scores.append(f1_score(y_test, y_pred_missforest, average='weighted'))\n",
    "\n",
    "#     clf_original = RandomForestClassifier(n_estimators=500)\n",
    "#     clf_original.fit(X_train, y_train)\n",
    "#     y_pred_original = clf_original.predict(X_test)\n",
    "#     print(\"Accuracy (original):\", accuracy_score(y_test, y_pred_original))\n",
    "#     ori_all_scores.append(accuracy_score(y_test, y_pred_original))\n",
    "#     ori_all_test_preds.extend(y_pred_original)\n",
    "#     ori_all_f1_scores.append(f1_score(y_test, y_pred_original, average='weighted'))\n",
    "\n",
    "#     clf_gain = RandomForestClassifier(n_estimators=500)\n",
    "#     clf_gain.fit(X_train_imputed_gain, y_train)\n",
    "#     y_pred_gain = clf_gain.predict(X_test)\n",
    "#     print(\"Accuracy (gain):\", accuracy_score(y_test, y_pred_gain))\n",
    "#     gain_all_scores.append(accuracy_score(y_test, y_pred_gain))\n",
    "#     gain_all_test_preds.extend(y_pred_gain)\n",
    "#     gain_all_f1_scores.append(f1_score(y_test, y_pred_gain, average='weighted'))\n",
    "\n",
    "#     clf_sinkhorn = RandomForestClassifier(n_estimators=500)\n",
    "#     clf_sinkhorn.fit(X_train_imputed_sinkhorn, y_train)\n",
    "#     y_pred_sinkhorn = clf_sinkhorn.predict(X_test)\n",
    "#     print(\"Accuracy (sinkhorn):\", accuracy_score(y_test, y_pred_sinkhorn))\n",
    "#     sinkhorn_all_scores.append(accuracy_score(y_test, y_pred_sinkhorn))\n",
    "#     sinkhorn_all_test_preds.extend(y_pred_sinkhorn)\n",
    "#     sinkhorn_all_f1_scores.append(f1_score(y_test, y_pred_sinkhorn, average='weighted'))\n",
    "\n",
    "#     clf_mean = RandomForestClassifier(n_estimators=500)\n",
    "#     clf_mean.fit(X_train_imputed_mean, y_train)\n",
    "#     y_pred_mean = clf_mean.predict(X_test)\n",
    "#     print(\"Accuracy (mean):\", accuracy_score(y_test, y_pred_mean))\n",
    "#     mean_all_scores.append(accuracy_score(y_test, y_pred_mean))\n",
    "#     mean_all_test_preds.extend(y_pred_mean)\n",
    "#     mean_all_f1_scores.append(f1_score(y_test, y_pred_mean, average='weighted'))\n",
    "\n",
    "#     y_test_all.extend(y_test)\n",
    "#     print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T06:34:01.917388Z",
     "start_time": "2024-05-09T06:34:00.428267Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # plot confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# fig, axs = plt.subplots(4, 2, figsize=(10, 12), sharex=True, sharey=True)\n",
    "# sns.set_theme(style=\"whitegrid\",font='Times New Roman',font_scale=1.5)\n",
    "\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# confusion_matrix_et = confusion_matrix(y_test_all, et_all_test_preds)\n",
    "# confusion_matrix_original = confusion_matrix(y_test_all, ori_all_test_preds)\n",
    "# confusion_matrix_hyper = confusion_matrix(y_test_all, hyper_all_test_preds)\n",
    "# confusion_matrix_missforest = confusion_matrix(y_test_all, missforest_all_test_preds)\n",
    "# confusion_matrix_gain = confusion_matrix(y_test_all, gain_all_test_preds)\n",
    "# confusion_matrix_sinkhorn = confusion_matrix(y_test_all, sinkhorn_all_test_preds)\n",
    "# confusion_matrix_mean = confusion_matrix(y_test_all, mean_all_test_preds)\n",
    "# cms = [confusion_matrix_original, confusion_matrix_et, confusion_matrix_hyper, confusion_matrix_missforest,\n",
    "#        confusion_matrix_gain, confusion_matrix_sinkhorn, confusion_matrix_mean]\n",
    "\n",
    "# methods = [\"Original\", \"MatImpute\", \"HyperImpute\", \"MissForest\", \"Gain\", \"Sinkhorn\", \"Mean\"]\n",
    "# scores = [ori_all_scores, et_all_scores, hyper_all_scores, missforest_all_scores, gain_all_scores, sinkhorn_all_scores,\n",
    "#           mean_all_scores]\n",
    "# f1_scores = [ori_all_f1_scores, et_all_f1_scores, hyper_all_f1_scores, missforest_all_f1_scores, gain_all_f1_scores,\n",
    "#              sinkhorn_all_f1_scores, mean_all_f1_scores]\n",
    "# classes = [\"building_float\", \"building_non_float\", \"vehicle_float\",\"containers\",\n",
    "#            \"tableware\", \"headlamps\"]\n",
    "# for i, ax in enumerate(axs[:len(cms)]):\n",
    "#     sns.heatmap(cms[i], annot=True, fmt='d', cmap='RdPu', ax=axs[i], xticklabels=classes,\n",
    "#                 yticklabels=classes, cbar=False, annot_kws={\"size\": 20})\n",
    "#     axs[i].set_title(\n",
    "#         \"{} ({:.2f}, {:.2f})\".format(methods[i], np.mean(scores[i]), np.mean(f1_scores[i])),fontsize=22)\n",
    "#     axs[i].tick_params(axis='x', labelsize=20)\n",
    "#     axs[i].tick_params(axis='y', labelsize=20, rotation=0)\n",
    "# # del the reamining axes\n",
    "# for i in range(len(cms), len(axs)):\n",
    "#     fig.delaxes(axs[i])\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.savefig(\"results/pipeline_cls_glass.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T06:34:01.923903Z",
     "start_time": "2024-05-09T06:34:01.918429Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(\"Accuracy (hyperimpute): {:.2f} ± {:.2f}\".format(np.mean(hyper_all_scores), np.std(hyper_all_scores)))\n",
    "# print(\"Accuracy (et): {:.2f} ± {:.2f}\".format(np.mean(et_all_scores), np.std(et_all_scores)))\n",
    "# print(\"Accuracy (missforest): {:.2f} ± {:.2f}\".format(np.mean(missforest_all_scores), np.std(missforest_all_scores)))\n",
    "# print(\"Accuracy (original): {:.2f} ± {:.2f}\".format(np.mean(ori_all_scores), np.std(ori_all_scores)))\n",
    "# print(\"Accuracy (gain): {:.2f} ± {:.2f}\".format(np.mean(gain_all_scores), np.std(gain_all_scores)))\n",
    "# print(\"Accuracy (sinkhorn): {:.2f} ± {:.2f}\".format(np.mean(sinkhorn_all_scores), np.std(sinkhorn_all_scores)))\n",
    "# print(\"Accuracy (mean): {:.2f} ± {:.2f}\".format(np.mean(mean_all_scores), np.std(mean_all_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T06:34:01.939430Z",
     "start_time": "2024-05-09T06:34:01.925701Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(\"F1 Score (hyperimpute): {:.2f} ± {:.2f}\".format(np.mean(hyper_all_f1_scores), np.std(hyper_all_f1_scores)))\n",
    "# print(\"F1 Score (et): {:.2f} ± {:.2f}\".format(np.mean(et_all_f1_scores), np.std(et_all_f1_scores)))\n",
    "# print(\"F1 Score (missforest): {:.2f} ± {:.2f}\".format(np.mean(missforest_all_f1_scores),\n",
    "#                                                       np.std(missforest_all_f1_scores)))\n",
    "# print(\"F1 Score (original): {:.2f} ± {:.2f}\".format(np.mean(ori_all_f1_scores), np.std(ori_all_f1_scores)))\n",
    "# print(\"F1 Score (gain): {:.2f} ± {:.2f}\".format(np.mean(gain_all_f1_scores), np.std(gain_all_f1_scores)))\n",
    "# print(\"F1 Score (sinkhorn): {:.2f} ± {:.2f}\".format(np.mean(sinkhorn_all_f1_scores), np.std(sinkhorn_all_f1_scores)))\n",
    "# print(\"F1 Score (mean): {:.2f} ± {:.2f}\".format(np.mean(mean_all_f1_scores), np.std(mean_all_f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T06:34:01.946611Z",
     "start_time": "2024-05-09T06:34:01.940496Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(\"Accuracy (hyperimpute):\", hyper_all_scores)\n",
    "# print(\"Accuracy (et):\", et_all_scores)\n",
    "# print(\"Accuracy (missforest):\", missforest_all_scores)\n",
    "# print(\"Accuracy (original):\", ori_all_scores)\n",
    "# print(\"Accuracy (gain):\", gain_all_scores)\n",
    "# print(\"Accuracy (sinkhorn):\", sinkhorn_all_scores)\n",
    "# print(\"Accuracy (mean):\", mean_all_scores)\n",
    "# print(\"=========================================\")\n",
    "# print(\"F1 Score (hyperimpute):\", hyper_all_f1_scores)\n",
    "# print(\"F1 Score (et):\", et_all_f1_scores)\n",
    "# print(\"F1 Score (missforest):\", missforest_all_f1_scores)\n",
    "# print(\"F1 Score (original):\", ori_all_f1_scores)\n",
    "# print(\"F1 Score (gain):\", gain_all_f1_scores)\n",
    "# print(\"F1 Score (sinkhorn):\", sinkhorn_all_f1_scores)\n",
    "# print(\"F1 Score (mean):\", mean_all_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:17<00:00, 75.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "target_col = \"Type of glass\"\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "original_scores = []\n",
    "matimpute_scores = []\n",
    "hyperimpute_scores = []\n",
    "missforest_scores = []\n",
    "gain_scores = []\n",
    "sinkhorn_scores = []\n",
    "mean_scores = []\n",
    "\n",
    "for ratio in tqdm([0.1, 0.2, 0.3, 0.4, 0.5]):\n",
    "    original_score = []\n",
    "    matimpute_score = []\n",
    "    hyperimpute_score = []\n",
    "    missforest_score = []\n",
    "    gain_score = []\n",
    "    sinkhorn_score = []\n",
    "    mean_score = []\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        df_train = pd.concat([X_train, y_train], axis=1)\n",
    "        df_test = pd.concat([X_test, y_test], axis=1)\n",
    "        # reset the index\n",
    "        df_train = df_train.reset_index(drop=True)\n",
    "        df_test = df_test.reset_index(drop=True)\n",
    "        X_train = df_train.drop(target_col, axis=1)\n",
    "        y_train = df_train[target_col]\n",
    "        X_test = df_test.drop(target_col, axis=1)\n",
    "        y_test = df_test[target_col]\n",
    "\n",
    "        cols = X_train.columns\n",
    "        X_train = X_train.to_numpy()\n",
    "        # np.random.seed(0)\n",
    "        X_train_nan = simulate_nan(X_train, ratio)['X_incomp']\n",
    "        X_train_nan = pd.DataFrame(X_train_nan, columns=cols)\n",
    "\n",
    "        X_train_imputed_hyper = hyper.fit_transform(X_train_nan.copy())\n",
    "        X_train_imputed_et = et.fit_transform(X_train_nan.copy())\n",
    "        X_train_imputed_missforest = missforest.fit_transform(X_train_nan.copy())\n",
    "        X_train_imputed_gain = gain.fit_transform(X_train_nan.copy())\n",
    "        X_train_imputed_sinkhorn = sinkhorn.fit_transform(X_train_nan.copy())\n",
    "        X_train_imputed_mean = mean.fit_transform(X_train_nan.copy())\n",
    "        \n",
    "        clf_original = RandomForestClassifier(n_estimators=500)\n",
    "        clf_original.fit(X_train, y_train)\n",
    "        y_pred_original = clf_original.predict(X_test)\n",
    "        original_score.append(accuracy_score(y_test, y_pred_original))\n",
    "\n",
    "        clf_et = RandomForestClassifier(n_estimators=500)\n",
    "        clf_et.fit(X_train_imputed_et, y_train)\n",
    "        y_pred_et = clf_et.predict(X_test)\n",
    "        matimpute_score.append(accuracy_score(y_test, y_pred_et))\n",
    "        \n",
    "        clf_hyper = RandomForestClassifier(n_estimators=500)\n",
    "        clf_hyper.fit(X_train_imputed_hyper, y_train)\n",
    "        y_pred_hyper = clf_hyper.predict(X_test)\n",
    "        hyperimpute_score.append(accuracy_score(y_test, y_pred_hyper))\n",
    "\n",
    "\n",
    "        clf_missforest = RandomForestClassifier(n_estimators=500)\n",
    "        clf_missforest.fit(X_train_imputed_missforest, y_train)\n",
    "        y_pred_missforest = clf_missforest.predict(X_test)\n",
    "        missforest_score.append(accuracy_score(y_test, y_pred_missforest))\n",
    "\n",
    "        clf_gain = RandomForestClassifier(n_estimators=500)\n",
    "        clf_gain.fit(X_train_imputed_gain, y_train)\n",
    "        y_pred_gain = clf_gain.predict(X_test)\n",
    "        gain_score.append(accuracy_score(y_test, y_pred_gain))\n",
    "\n",
    "\n",
    "        clf_sinkhorn = RandomForestClassifier(n_estimators=500)\n",
    "        clf_sinkhorn.fit(X_train_imputed_sinkhorn, y_train)\n",
    "        y_pred_sinkhorn = clf_sinkhorn.predict(X_test)\n",
    "        sinkhorn_score.append(accuracy_score(y_test, y_pred_sinkhorn))\n",
    "\n",
    "\n",
    "        clf_mean = RandomForestClassifier(n_estimators=500)\n",
    "        clf_mean.fit(X_train_imputed_mean, y_train)\n",
    "        y_pred_mean = clf_mean.predict(X_test)\n",
    "        mean_score.append(accuracy_score(y_test, y_pred_mean))\n",
    "    original_scores.append(original_score)\n",
    "    matimpute_scores.append(matimpute_score)\n",
    "    hyperimpute_scores.append(hyperimpute_score)\n",
    "    missforest_scores.append(missforest_score)\n",
    "    gain_scores.append(gain_score)\n",
    "    sinkhorn_scores.append(sinkhorn_score)\n",
    "    mean_scores.append(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "\n",
    "results = [\n",
    "    original_scores,\n",
    "    matimpute_scores,\n",
    "    hyperimpute_scores,\n",
    "    missforest_scores,\n",
    "    gain_scores,\n",
    "    sinkhorn_scores,\n",
    "    mean_scores\n",
    "]\n",
    "\n",
    "# save to npy file\n",
    "np.save(\"results/results_glass.npy\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the results\n",
    "# import scienceplots\n",
    "\n",
    "# plt.style.use('default')\n",
    "# plt.style.use(['science','no-latex'])\n",
    "# # set font as times new roman\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# plt.figure(figsize=(8, 6))\n",
    "\n",
    "# # # set no grid\n",
    "# plt.grid(False)\n",
    "\n",
    "# sns.lineplot(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=original_scores, label='Original', marker='o',color='#7ED9D9',lw=2, markersize=8)\n",
    "# sns.lineplot(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=matimpute_scores, label='MatImpute', marker='*',color='#F35F5F',lw=2, markersize=12)\n",
    "# sns.lineplot(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=hyperimpute_scores, label='HyperImpute', marker='v',color='#9467BD',lw=2, markersize=8)\n",
    "# sns.lineplot(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=missforest_scores, label='MissForest', marker='^',color='#B3DE69',lw=2, markersize=8)\n",
    "# sns.lineplot(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=gain_scores, label='Gain', marker='>',color='#FFC0D9',lw=2, markersize=8)\n",
    "# sns.lineplot(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=sinkhorn_scores, label='Sinkhorn', marker='<',color='#5FBDFF',lw=2, markersize=8)\n",
    "# sns.lineplot(x=[0.1, 0.2, 0.3, 0.4, 0.5], y=mean_scores, label='Mean', marker='s',color='#FDBF6E',lw=2, markersize=7)\n",
    "\n",
    "# plt.xlabel('Missing Ratio', fontsize=24)\n",
    "# plt.ylabel('Accuracy',fontsize=24)\n",
    "# plt.tick_params(labelsize=24)\n",
    "# plt.legend([])\n",
    "# plt.tight_layout(pad=1.5)\n",
    "# plt.savefig(\"results/missing_ratio_cls_glass.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
